{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45400ed7-a924-4fcf-978f-e66710b6deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.reset()\n",
    "plt.imshow(env.render(mode=\"rgb_array\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97ee7680-08fb-41ed-a653-733fe4eea1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        index = np.random.choice(np.arange(buffer_size),\n",
    "                                 size=batch_size,\n",
    "                                 replace=False)\n",
    "        return [self.buffer[i] for i in index]\n",
    "    \n",
    "    def get_all(self):\n",
    "        return [self.buffer[i] for i in range(len(self.buffer))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab4d1b68-13db-489b-8968-a0dabe048f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(tf.keras.Model):\n",
    "    def __init__(self, env, training=True):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.inputs = layers.Input(shape=(8,))\n",
    "        self.fc1 = layers.Dense(50, activation=\"relu\")\n",
    "        self.fc2 = layers.Dense(50, activation=\"relu\")\n",
    "        self.actor = layers.Dense(4, activation=\"linear\")\n",
    "        self.critic = layers.Dense(1, activation=\"linear\")\n",
    "        \n",
    "        self.env = env\n",
    "        \n",
    "        self.training = training\n",
    "        self.opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.fc2(inputs)\n",
    "        actions = self.actor(x)\n",
    "        value = self.critic(x)\n",
    "        return actions, value\n",
    "    \n",
    "    def select_action(self, inputs, episode):\n",
    "        \n",
    "        max_epsilon = 0.5             # Exploration probability at start\n",
    "        min_epsilon = 0            # Minimum exploration probability \n",
    "        decay_rate = 0.003          # Exponential decay rate for exploration prob\n",
    "        \n",
    "        # random number for explore/exploit trade-off\n",
    "        epsilon = np.random.rand()\n",
    "\n",
    "        # current ee prob\n",
    "        explore_prob = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate*episode)\n",
    "        \n",
    "        action_logits, value = self.call(tf.expand_dims(inputs, axis=0))\n",
    "        \n",
    "        # choose random action or max action_probs, epsilon greedy\n",
    "        if epsilon < explore_prob and self.training:\n",
    "            action = self.env.action_space.sample()\n",
    "        \n",
    "        else:\n",
    "            action = tf.random.categorical(action_logits, 1)[0, 0].numpy()\n",
    "        \n",
    "        return action, tf.nn.softmax(action_logits), value\n",
    "    \n",
    "    def train_step(self, state, episode):\n",
    "        \n",
    "        action, action_probs, value = self.select_action(state, episode)\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "        log_action = tf.math.log(tf.squeeze(action_probs)[action])\n",
    "        \n",
    "        return action, log_action, value, next_state, reward, done\n",
    "        \n",
    "        \n",
    "    def learn(self, rewards, log_actions, values, Vt):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            # update value estimates\n",
    "            for t in reversed(range(len(rewards)+1)):\n",
    "                Vt = rewards[t] + (gamma * Vt)\n",
    "                Vs = Vs.write(t, Vt)\n",
    "\n",
    "            Vs = Vs.stack()\n",
    "            Vs = (Vs - tf.math.reduce_mean(Vs)) / (tf.math.reduce_std(Vs) + 1e-9)\n",
    "\n",
    "            actor_loss = -tf.math.reduce_sum(log_actions * (Vs-values))\n",
    "            critic_loss = tf.keras.losses.Huber()(tf.squeeze(values), Vs)\n",
    "            loss = actor_loss + critic_loss\n",
    "\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def train(self, episodes, max_steps=200):\n",
    "        episode_reward_hist = np.zeros(episodes)\n",
    "        loss_hist = []\n",
    "\n",
    "        for episode in range(episodes):          \n",
    "            \n",
    "            step = 0\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            \n",
    "            rewards = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "            log_actions = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "            values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "            Vs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "            \n",
    "            while not done and step < max_steps:\n",
    "                \n",
    "                action, log_action, value, next_state, reward, done = self.train_step(state, episode)\n",
    "                \n",
    "                rewards = rewards.write(step, reward)\n",
    "                log_actions = log_actions.write(step, log_action)\n",
    "                values = values.write(step, value)\n",
    "\n",
    "                episode_reward += reward\n",
    "                step +=1\n",
    "        \n",
    "            rewards = rewards.stack()\n",
    "            log_actions = log_actions.stack()\n",
    "            values = values.stack()\n",
    "            Vt = tf.constant(0.0)\n",
    "            \n",
    "            loss = self.learn(rewards, log_actions, values, Vt)\n",
    "            loss_hist.append(loss)\n",
    "            episode_reward_hist[episode] = episode_reward\n",
    "            \n",
    "            if episode % 1 == 0:\n",
    "                print(f\"Episode:{episode}, Loss: {(actor_loss.numpy(), critic_loss.numpy())}, Ep reward:{episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1565e7bf-136e-4f59-9b4d-4b9cedffab78",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index 141 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-c6d5707eb8f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mActorCritic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-72828bec2e95>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, episodes, max_steps)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mVt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[0mloss_hist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mepisode_reward_hist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepisode_reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-72828bec2e95>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, rewards, log_actions, values, Vt)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;31m# update value estimates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                 \u001b[0mVt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mVt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m                 \u001b[0mVs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1038\u001b[0m       \u001b[0mvar_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0mpacked_begin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacked_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacked_strides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m     return strided_slice(\n\u001b[0m\u001b[0;32m   1041\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m         \u001b[0mpacked_begin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m   op = gen_array_ops.strided_slice(\n\u001b[0m\u001b[0;32m   1214\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10502\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10503\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10504\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10505\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10506\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6896\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6897\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6898\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: slice index 141 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "ac = ActorCritic(env)\n",
    "ac.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ed689b0-ad04-44db-82ad-db7a8a7702e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'action_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-69eb1bc894c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-ae038e38bf2e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, episodes, max_steps)\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                 \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-ae038e38bf2e>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, state, episode)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mlog_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'action_prob' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a281eef5-fe9c-4810-8a13-6137aeaec29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00380335,  1.4052917 , -0.38524708, -0.25016204,  0.00441386,\n",
       "        0.08726414,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba588edc-9f3e-4153-8ffc-276ddfcbce5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
